# Content Recommendation System
**Quick Summary**: In this project I predict user ratings through memory based filtering and matrix factorization. This repository contains a Jupyter notebook where you'll find all the relevant code as well as a 4 min. video presentation I put together (as an alternative to the text below) that summarizes the steps taken and findings of this project. 

## The Business Opportunity 
Streaming platforms have been making use of recommendation systems since the beginning of their relatively young industry. However, according to to WarnerMedia’s  chief technology officer there’s still a lot of room for improvement: “It’s been tried through algorithms to provide recommendations to consumers… but I don’t think the sweet spot has been hit yet.”

There are quite a few reasons why it may feel like the sweet spot hasn’t been hit yet. For instance, Netflix continues to dedicate resources to tuning how it makes recommendations as evidenced during a recent conference call with investors where Netflix disclosed that a majority of the 400 A/B tests they run a year are devoted to doing a better job recommending content. A perceived inability for streaming platforms to connect appropriate users to their content has led to some filmmakers being unwilling to sell their content to streaming platforms. Lulu Wang, the director of the movie The Farewell, said during a roundtable discussion that she had been offered more money by a major streaming platform for her film, but opted to go a smaller studio because she felt like her content would get lost within the platform’s library. From a consumer perspective, according to a survey by Nielson, one-third of customers do not know what they want to watch when signing in to a platform and a proportion of these customers also report exiting the service without having been able to find something they’d like to watch. 

## How This Has Been Addressed In The Past 
In trying to hit that sweet spot that WarnerMedia’s CTO mentioned, platforms have tended to take one of three approaches. The first is to rely completely on algorithms built by data scientists in order to make recommendations to a customer. The two other methods include relying completely on human only curation or a mixture of algorithms and human curation

## The Goal 
With all this in mind, my overall objective when undertaking this project is to design a complete recommendation system that is superior to the those currently in place at major streaming platforms such as Netflix and Disney (i.e. one that hits that “sweet spot”). The goal of this specific project, within the scope of my overall objective, is to build a model that is capable of predicting the ratings users would give to content they’ve never seen before. In doing so, I will have built a platform on which I can begin to build my complete system around. 

## Data Collection 
The data required to complete this project was acquired through MovieLens, a website that has been collecting data related to the topic of recommendation systems in the field of movies for almost 20 years. The data itself came in the form of two CSV files titled ‘movies’ and ‘ratings’. The former contained the titles of nearly 10,000 movies, their respective IDs, and the genre of each movie. The latter file contained the IDs of hundreds of users, the ratings they gave to movies from a scale of 0.5 – 5, and the ID of the  movie that was rated. 

## Data Preprocessing and Cleaning 
The first step I took after gathering the data was to search it for any NaN or duplicate values. While there weren’t any NaN values to deal with, I did find several duplicated titles within my set of movie titles. After noticing that the duplicated titles also had their own unique IDs, I cross referenced the IDs of those movies with those in the ratings table and discovered that the duplicated titles had their votes split among different movie IDs. Resolving this issue involved changing the movie IDs’ of duplicated titles in the ratings table to match the IDs of the first instance of those duplicates and then deleting those duplicate titles and IDs from the data set.

The final action taken in this step of the project was to investigate the distribution of the ratings. The ratings followed a normal distribution so no adjustments were made. 
	
## Data Analysis 
Before jumping into modeling, I took some time to analyze the data in order to better understand the figures I was dealing with. I started off by studying the ratings table and identifying the average number of ratings made by a reviewer as well as the relationship between the  number of movies rated and average rating given by a user. I then identified how often each movie was rated, the average rating of each movie , and the relationships between a movie’s average rating with the number of reviews it received. Doing so helped me make more informed decision when deciding on cutoff values, having an idea of which users I can expect to come up with larger lists of recommendations for, and which movie/users would have similarity scores based on relatively fewer data points when I began modeling. For some interesting visuals related to this data analysis please see the Jupyter Notebook included within this final submission.

## Modeling
There were four different models that I investigated during this project. The first model was based on content based filtering and the other three were all variations of collaborative filtering. 

The content based filtering model used the data from the data frame titled ‘movies’  (i.e. the movie name and genre) in order to make recommendations. Since this model bases its recommendations on some common feature between movies that a user liked in the past, I used the genre of each movie as the common feature. The benefits of this model included its ability to recommend items that capture the specific interests of a user and the transparency behind the decision making. A few disadvantages of this model were its inability to recommend new interests to users as well as the inability to quantify how well it worked using measures such as RMSE and MAE. 

The first two variations of collaborative filtering that I used made predictions using similarity scores that were calculated between the movies (item-item based collaborative filtering) or between the users (user-user based collaborative filtering). The third variation (referred to as SVD based collaborative filtering) treated the goal of predicting ratings as an optimization problem and thus required the tuning of hyper parameters. Once the models were set up and run we were able to produce recommendations for each user. 

In evaluating the collaborative filtering models there were two things I considered. First, was the accuracy of each model, which I evaluated using the RMSE and MAE. Based on those results, the SVD based version was the most accurate. The second consideration was run-time, which is vital to consider since streaming platforms have customers that expect to receive new recommendations on a daily basis. While it took the first two variations several days to run (when using the entire data set), the SVD based version only took 20 minutes! 

## Findings and conclusions
Based on the results of each model with regards to their accuracy and run-time, the SVD based model is the most viable option to build a complete recommendation system around. However, based on my initial goal of building a model on top of which I could create a fully functional recommendation system, my SVD model’s accuracy score wasn’t nearly high enough. 

## Summary and Next Steps
My overall objective continues to be to build a recommendation system that meets the needs of stakeholders within the streaming industry better than systems currently being used today. However, the model I hoped to build my system around wasn’t as accurate as I’d hoped and thus my next step will be to improve my model’s accuracy by investigating model’s that take advantage of deep learning techniques and to then incorporate those models along with my SVD based model with the intention of building a finalized hybrid model that produces significantly higher accuracy scores. Once that is done, I’ll continue to build my recommendation system by implementing solutions that assist in making recommendations where my model fails (such as instances where new users who we do not have information about join the platform) as well as continuing to tune the model. Eventually, I would like to launch my finalized system online and allow users to sign up and receive recommendations. Based on user feedback and I will continue to adjust the recommendation system until it is capable of filling that industry sweet spot. 
